# RAGAS Metrics Report

RAGAS 라이브러리에서 제공하는 세 가지 평가 지표(metrics)에 대해 관한 내용.
각 지표는 대형 언어 모델(LLM)의 성능과 출력의 정확성을 평가하기 위해 사용된다. 여기서는 실습에서 사용되는 **LLMContextCall**, **FactualCorrectness**, 그리고 추가적으로 **Relevance** 지표에 대해 다룬다.

---

## 1. LLMContextCall

**LLMContextCall**은 모델이 주어진 문맥(context)과 얼마나 일치하는지 평가하는 지표이다. 이 지표는 모델이 문맥에 기반하여 정확한 답변을 생성하는 능력을 평가하는 데 중점을 둔다. LLMContextCall은 모델이 주어진 문맥을 충분히 이해하고, 문맥과 일관성 있는 응답을 생성하는지 확인하기 위해 활용된다.

- **목적**: 문맥 기반 평가
- **평가 방식**: 모델의 응답이 주어진 문맥과 직접적으로 관련되는지 여부를 판단
- **활용 예시**: 특정 질문에 대해 이전 문맥이 주어졌을 때, 모델이 그 문맥을 참고하여 적절한 답변을 제공하는지 평가하는 데 유용하다.

---

## 2. FactualCorrectness

**FactualCorrectness**는 모델의 출력이 사실적으로 정확한지 평가하는 지표이다. 모델이 생성한 답변이 사실에 기반하며 정확한 정보를 제공하는지를 측정하며, 특히 정보의 신뢰성이 중요한 응용 분야에서 필수적인 평가 항목이다.

- **목적**: 정보의 사실적 정확성 평가
- **평가 방식**: 모델이 제공한 답변이 주어진 사실 정보와 일치하는지 확인
- **활용 예시**: 정보 검색 시스템에서 사용자 질문에 대한 답변이 외부 데이터베이스나 신뢰할 수 있는 출처와 일치하는지 확인할 때 사용된다.

---

## 3. Relevance (추가 지표)

**Relevance**는 모델의 응답이 사용자의 질문에 얼마나 적절하고 관련성이 있는지를 평가하는 지표이다. 이 지표는 모델이 질문과 무관한 정보를 제공하는 것을 방지하며, 사용자가 기대하는 응답과의 관련성을 중점적으로 측정한다.

- **목적**: 응답의 관련성 평가
- **평가 방식**: 모델의 답변이 질문과의 연관성 여부에 따라 평가
- **활용 예시**: 고객 지원 시스템에서 사용자가 특정 문제를 문의할 때, 관련성이 높은 정보를 제공할 수 있는지 평가하는 데 유용하다.


